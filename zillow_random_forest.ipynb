{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirasmitty/Project_Zillow/blob/main/zillow_random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYqc6AXGLlj2"
      },
      "source": [
        "# Instructor Do: Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#USING SPARK VIA GOOGLE COLLAB CODE TO MAKE IT WORK\n",
        "import os\n",
        "# Find the latest version of spark 3.x  from https://downloads.apache.org/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.5.1'\n",
        "spark_version = 'spark-3.5.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KT4MHStMnWQ",
        "outputId": "0f9f53eb-7e02-412b-c46c-851be8edefd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.83)] [Waiting for headers] [C\r                                                                                                    \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXkzkOtpLlj4"
      },
      "outputs": [],
      "source": [
        "# Initial imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"ZillowData\").getOrCreate()"
      ],
      "metadata": {
        "id": "2mux7Qlpavmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Read in the AWS S3 bucket into a DataFrame.\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://raw.githubusercontent.com/mirasmitty/Project_Zillow/main/Resources/Zillow_data_Detroit.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Zillow_data_Detroit.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrssb2qfa2SJ",
        "outputId": "75731abc-9790-4097-d5ab-074cc625be30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------------------------+-------------------------------+\n",
            "|Week of pending|Mean days listing to pending|Mean price reduction percentage|\n",
            "+---------------+----------------------------+-------------------------------+\n",
            "|      1/27/2018|                          49|                    0.045619162|\n",
            "|       2/3/2018|                          48|                    0.046532464|\n",
            "|      2/10/2018|                          47|                    0.048535741|\n",
            "|      2/17/2018|                          46|                    0.049168844|\n",
            "|      2/24/2018|                          43|                    0.048167891|\n",
            "|       3/3/2018|                          42|                    0.047288417|\n",
            "|      3/10/2018|                          40|                     0.04445831|\n",
            "|      3/17/2018|                          38|                    0.042958179|\n",
            "|      3/24/2018|                          37|                    0.042379745|\n",
            "|      3/31/2018|                          35|                    0.041987246|\n",
            "|       4/7/2018|                          32|                    0.042493631|\n",
            "|      4/14/2018|                          30|                    0.042185841|\n",
            "|      4/21/2018|                          27|                    0.042465899|\n",
            "|      4/28/2018|                          26|                    0.041179178|\n",
            "|       5/5/2018|                          24|                     0.03971423|\n",
            "|      5/12/2018|                          24|                    0.040623219|\n",
            "|      5/19/2018|                          23|                    0.039831881|\n",
            "|      5/26/2018|                          23|                    0.039996322|\n",
            "|       6/2/2018|                          23|                     0.04086479|\n",
            "|       6/9/2018|                          24|                    0.039733135|\n",
            "+---------------+----------------------------+-------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print our schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqtDZaUIbSP9",
        "outputId": "e0e632e2-2210-42c3-f921-c1542553c609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Week of pending: string (nullable = true)\n",
            " |-- Mean days listing to pending: string (nullable = true)\n",
            " |-- Mean price reduction percentage: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqJIRCW8Llj5"
      },
      "source": [
        "## Loading and Preprocessing Loans Encoded Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUfYp7o2Llj5",
        "outputId": "d643a637-ed16-4a3b-b696-e7ba48cf826b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Week of pending', 'string'),\n",
              " ('Mean days listing to pending', 'string'),\n",
              " ('Mean price reduction percentage', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNqZe3O8Llj5",
        "outputId": "d8c3131a-0212-4ac1-c6fa-37ce4150440d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "315"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyPX0ZkrLlj6",
        "outputId": "c26e9bea-7b83-4003-96cd-80bf7ab27a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------------------------+\n",
            "|Week of pending|Mean days listing to pending|\n",
            "+---------------+----------------------------+\n",
            "|      1/27/2018|                          49|\n",
            "|       2/3/2018|                          48|\n",
            "|      2/10/2018|                          47|\n",
            "|      2/17/2018|                          46|\n",
            "|      2/24/2018|                          43|\n",
            "|       3/3/2018|                          42|\n",
            "|      3/10/2018|                          40|\n",
            "|      3/17/2018|                          38|\n",
            "|      3/24/2018|                          37|\n",
            "|      3/31/2018|                          35|\n",
            "|       4/7/2018|                          32|\n",
            "|      4/14/2018|                          30|\n",
            "|      4/21/2018|                          27|\n",
            "|      4/28/2018|                          26|\n",
            "|       5/5/2018|                          24|\n",
            "|      5/12/2018|                          24|\n",
            "|      5/19/2018|                          23|\n",
            "|      5/26/2018|                          23|\n",
            "|       6/2/2018|                          23|\n",
            "|       6/9/2018|                          24|\n",
            "+---------------+----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define features set\n",
        "x = df.drop(\"Mean price reduction percentage\")\n",
        "\n",
        "x.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcR6Kmi_Llj6",
        "outputId": "52816a9b-cb7e-4622-9faf-654334f1e9f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0.045619162', '0.046532464', '0.048535741', '0.049168844', '0.048167891']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Define target vector\n",
        "y = df.select(\"Mean price reduction percentage\").rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "#y = df[\"Mean price reduction percentage\"].ravel()\n",
        "\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "xeG_28XILlj6"
      },
      "outputs": [],
      "source": [
        "# Splitting into Train and Test sets\n",
        "# Splitting into Train and Test sets train_data,\n",
        "\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=78)\n",
        "\n",
        "x_train = train_data.select(\"Week of pending\", \"Mean days listing to pending\")\n",
        "y_train = train_data.select(\"Mean price reduction percentage\")\n",
        "x_test = test_data.select(\"Week of pending\", \"Mean days listing to pending\")\n",
        "y_test = test_data.select(\"Mean price reduction percentage\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sSMN32a6Llj6"
      },
      "outputs": [],
      "source": [
        "# Creating StandardScaler instance\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "MQDy0PPALlj6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "b9b4f43f-2464-4d6c-ba0d-49bb4ee3a198"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "StandardScaler.__init__() got an unexpected keyword argument 'inputCol'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f23f6c1fe5db>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize the StandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Week of pending\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mean days listing to pending\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scaled_features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithMean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithStd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: StandardScaler.__init__() got an unexpected keyword argument 'inputCol'"
          ]
        }
      ],
      "source": [
        "# Fitting Standard Scaler\n",
        "#x_scaler = scaler.fit(x_train)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler(inputCol=(\"Week of pending\", \"Mean days listing to pending\"), outputCol=\"scaled_features\", withMean=True, withStd=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR0podeiLlj7"
      },
      "outputs": [],
      "source": [
        "# Scaling data\n",
        "x_train_scaled = x_scaler.transform(x_train)\n",
        "x_test_scaled = x_scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWhRx-xiLlj7"
      },
      "source": [
        "## Fitting the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKJCj9zzLlj7"
      },
      "outputs": [],
      "source": [
        "# Create a random forest classifier\n",
        "rf_model = RandomForestRegressor(n_estimators=500, random_state=78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTG-Zr25Llj7"
      },
      "outputs": [],
      "source": [
        "# Fitting the model\n",
        "rf_model = rf_model.fit(x_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksbf_Vu0Llj7"
      },
      "source": [
        "## Making Predictions Using the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QpYc_VPLlj7"
      },
      "outputs": [],
      "source": [
        "# Making predictions using the testing data\n",
        "predictions = rf_model.predict(x_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5IEUjuxLlj7"
      },
      "outputs": [],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv17JoHvLlj7"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo9yjJx9Llj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owFuqS6DLlj7"
      },
      "outputs": [],
      "source": [
        "# Compute the metrics for the Random forest regression model\n",
        "score = rf_model.score(x_test, y_test,sample_weight=None)\n",
        "r2 = r2_score(y_test,predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "std = np.std(y_test)\n",
        "error = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "# Print relevant metrics.\n",
        "print(f\"The score is {score}.\")\n",
        "print(f\"The r2 is {r2}.\")\n",
        "print(f\"The mean squared error is {mse}.\")\n",
        "print(f\"The root mean squared error is {rmse}.\")\n",
        "print(f\"The standard deviation is {std}.\")\n",
        "print(f\"The error is {error} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcfPWg-Llj7"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpdPFkzELlj7"
      },
      "outputs": [],
      "source": [
        "# Random Forests in sklearn will automatically calculate feature importance\n",
        "imprtances = rf_model.feature_importances_\n",
        "# We can sort the features by their importance\n",
        "sorted(zip(rf_model.feature_importances_, x.columns), reverse= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56wzrcTmLlj7"
      },
      "outputs": [],
      "source": [
        "# Visualize the features by importance\n",
        "importances_df = pd.DataFrame(sorted(zip(rf_model.feature_importances_, x.columns), reverse = True))\n",
        "importances_df.set_index(importances_df[1], inplace = True)\n",
        "importances_df.drop(columns = 1, inplace = True)\n",
        "importances_df.rename(columns = {0: 'Feature Importances'}, inplace = True)\n",
        "importances_sorted = importances_df.sort_values(by = 'Feature Importances')\n",
        "importances_sorted.plot(kind = 'barh', color = 'lightgreen', title = 'Features Importances', legend = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape\")\n",
        "print(\"Training data : \", df.shape)\n",
        "print(\"Test data     : \", df.shape)"
      ],
      "metadata": {
        "id": "bmZfaw38QB4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = (df.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "print(\"Categorical variables:\")\n",
        "print(object_cols)\n",
        "\n",
        "s = (df.dtypes == 'int')\n",
        "num_cols = list(s[s].index)\n",
        "print(\"Integer variables:\")\n",
        "print(num_cols)\n",
        "\n",
        "s = (df.dtypes == 'float')\n",
        "num_cols = list(s[s].index)\n",
        "print(\"Real variables:\")\n",
        "print(num_cols)"
      ],
      "metadata": {
        "id": "ubN3NaNXQBsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "IA8c8cgkMLVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "plt.title('Heatmap of missing values')\n",
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
      ],
      "metadata": {
        "id": "P1UZMrszMXay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = []\n",
        "for col in object_cols:\n",
        "  unique_values.append(df[col].unique().size)\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.title('No. Unique values of Categorical Features')\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x=object_cols,y=unique_values)"
      ],
      "metadata": {
        "id": "TCiwzzdGMZpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,36))\n",
        "plt.title('Categorical Features: Distribution')\n",
        "plt.xticks(rotation=90)\n",
        "index = 1\n",
        "for col in object_cols:\n",
        "  y = df_combined[col].value_counts()\n",
        "  plt.subplot(11,4,index)\n",
        "  plt.xticks(rotation=90)\n",
        "  sns.barplot(x=list(y.index), y=y)\n",
        "  index +=1"
      ],
      "metadata": {
        "id": "4s6rssMZMcDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fill up missing values:**\n",
        "* Drop the features 'Alley', 'Fence', and 'MiscFeature'.\n",
        "\n",
        "* Drop 'Utilities' feature, as all but one have the value 'AllPub'\n",
        "\n",
        "* All entries with missing 'FirePlaceQu' have 'Fireplaces' = 0. Hence fill missing values with 'NA'.\n",
        "\n",
        "* All but one entries with missing 'PoolQC' value have 'PoolArea' = 0. Use mode for missing value with non-zero PoolArea. Use 'NA' for the rest of the entries.\n",
        "\n",
        "* **Basement features:** Fill missing values with 'NA' or '0'.\n",
        "\n",
        "* **Garage features:** Fill missing values with 'NA' or '0'.\n",
        "\n",
        "* **Remaining Integer and Real features:** fill up missing values with mean of the corresponding feature.\n",
        "\n",
        "* **Remaining Categorical features:** fill up missing values with mode of the corresponding feature."
      ],
      "metadata": {
        "id": "sPuo673zMgOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_combined.drop(columns='Id',inplace=True); print('Drop Id \\n')\n",
        "#df_combined['MSZoning'] = df_combined['MSZoning'].fillna(df_combined['MSZoning'].mode()[0])\n",
        "#df_combined['LotFrontage'] = df_combined['LotFrontage'].fillna(df_combined['LotFrontage'].mean())\n",
        "#df_combined.drop(columns='Alley',inplace=True); print('Drop Alley \\n')\n",
        "\n",
        "#df_combined['Utilities'] = df_combined['Utilities'].fillna(df_combined['Utilities'].mode()[0])\n",
        "#print(df_combined['Utilities'].value_counts())\n",
        "#df_combined.drop(columns='Utilities',inplace=True); print('Drop Utilities \\n')\n",
        "\n",
        "#df_combined['Exterior1st'] = df_combined['Exterior1st'].fillna(df_combined['Exterior1st'].mode()[0])\n",
        "#df_combined['Exterior2nd'] = df_combined['Exterior2nd'].fillna(df_combined['Exterior2nd'].mode()[0])\n",
        "#df_combined['MasVnrType'] = df_combined['MasVnrType'].fillna(df_combined['MasVnrType'].mode()[0])\n",
        "#df_combined['MasVnrArea'] = df_combined['MasVnrArea'].fillna(df_combined['MasVnrArea'].mean())\n",
        "#df_combined['Electrical'] = df_combined['Electrical'].fillna(df_combined['Electrical'].mode()[0])\n",
        "#df_combined['KitchenQual'] = df_combined['KitchenQual'].fillna(df_combined['KitchenQual'].mode()[0])\n",
        "#df_combined['Functional'] = df_combined['Functional'].fillna(df_combined['Functional'].mode()[0])\n",
        "\n",
        "#df_combined.loc[(df_combined['Fireplaces'] != 0) & (df_combined['FireplaceQu'].isnull()) ][['FireplaceQu','Fireplaces']]\n",
        "#df_combined['FireplaceQu'] = df_combined['FireplaceQu'].fillna('NA'); print('FirePlaceQu: Fill NA values for missing values \\n')\n",
        "\n",
        "#df_combined.loc[(df_combined['PoolQC'].isnull()) & df_combined['PoolArea']>0][['PoolQC','PoolArea']]\n",
        "#df_combined.at[2599,'PoolQC'] = df_combined['PoolQC'].mode()[0]; print('PoolQC: Use mode for missing value with non-zero PoolAre \\n')\n",
        "#df_combined['PoolQC'] = df_combined['PoolQC'].fillna('NA'); print('PoolQC: Use NA for remaining missing values \\n')\n",
        "\n",
        "#df_combined['SaleType'].fillna(df_combined['SaleType'].mode()[0],inplace=True)\n",
        "#df_combined.drop(columns=['Fence','MiscFeature','SalePrice'],inplace=True); print('Drop Fence, MiscFeature and SalePrice\\n')\n",
        "\n",
        "# Basement Features\n",
        "#df_combined.loc[df_combined['BsmtQual'].isnull()][['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']].head()\n",
        "#df_combined.loc[df_combined['TotalBsmtSF'].isnull()][['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']]\n",
        "#print('Fill missing values of Basement features with NA or 0 \\n')\n",
        "#df_combined['BsmtQual'] = df_combined['BsmtQual'].fillna('NA')\n",
        "#df_combined['BsmtCond'] = df_combined['BsmtCond'].fillna('NA')\n",
        "#df_combined['BsmtExposure'] = df_combined['BsmtExposure'].fillna('NA')\n",
        "#df_combined['BsmtFinType1'] = df_combined['BsmtFinType1'].fillna('NA')\n",
        "#df_combined['BsmtFinType2'] = df_combined['BsmtFinType2'].fillna('NA')\n",
        "\n",
        "#df_combined['BsmtFinSF1'] = df_combined['BsmtFinSF1'].fillna(int(0))\n",
        "#df_combined['BsmtFinSF2'] = df_combined['BsmtFinSF2'].fillna(int(0))\n",
        "#df_combined['BsmtUnfSF'] = df_combined['BsmtUnfSF'].fillna(int(0))\n",
        "#df_combined['TotalBsmtSF'] = df_combined['TotalBsmtSF'].fillna(int(0))\n",
        "#df_combined['BsmtFullBath'] = df_combined['BsmtFullBath'].fillna(int(0))\n",
        "#df_combined['BsmtHalfBath'] = df_combined['BsmtHalfBath'].fillna(int(0))\n",
        "\n",
        "# Garage Features\n",
        "# df_combined.loc[df_combined['GarageCond'].isnull()][['GarageType','GarageYrBlt','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond']].head()\n",
        "#print('Fill missing values of Garage features with NA or 0 \\n')\n",
        "#df_combined['GarageType'] = df_combined['GarageType'].fillna('NA')\n",
        "#df_combined['GarageFinish'] = df_combined['GarageFinish'].fillna('NA')\n",
        "#df_combined['GarageCond'] = df_combined['GarageCond'].fillna('NA')\n",
        "#df_combined['GarageQual'] = df_combined['GarageQual'].fillna('NA')\n",
        "#df_combined['GarageCars'] = df_combined['GarageCars'].fillna(int(0))\n",
        "#df_combined['GarageArea'] = df_combined['GarageArea'].fillna(int(0))\n",
        "#df_combined['GarageYrBlt'] = df_combined['GarageYrBlt'].fillna(int(0))"
      ],
      "metadata": {
        "id": "qwHXnGJTNQ8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "OReqr39BNTks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check that all missing values have been taken care of.\n"
      ],
      "metadata": {
        "id": "xnm4vgYQNYvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum().sum())\n"
      ],
      "metadata": {
        "id": "RzrzLANKNbay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "PP8q8JFXNfIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import Onehot encoder to encode categorical features\n"
      ],
      "metadata": {
        "id": "0D9X6tKWNjsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "metadata": {
        "id": "kEmsZkBLNmFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = (df.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "print(\"Categorical variables:\")\n",
        "print(object_cols)\n",
        "print('No. of. categorical features: ',len(object_cols))"
      ],
      "metadata": {
        "id": "quvHFt4tNn_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "df[cat].nunique()"
      ],
      "metadata": {
        "id": "__lv7QMXSqPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(sparse=False)\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(df[cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe\n",
        "encode_df.columns = enc.get_feature_names_out(cat)\n",
        "encode_df.head()"
      ],
      "metadata": {
        "id": "x90Z7UnQSJMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OH_encoder = OneHotEncoder(sparse=False)\n",
        "OH_cols = pd.DataFrame(OH_encoder.fit_transform(df[object_cols]))\n",
        "OH_cols.index = df.index\n",
        "OH_cols.columns = OH_encoder.get_feature_names_out()\n",
        "df_final = df.drop(object_cols, axis=1)\n",
        "df_final = pd.concat([df_final, OH_cols], axis=1)"
      ],
      "metadata": {
        "id": "o_ebrPvZNqOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.head()"
      ],
      "metadata": {
        "id": "sQ42RcK5Nr2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the shapes are consistent\n",
        "\n",
        "print('df_final shape:', df_final.shape)\n",
        "print('df_train shape:', df.shape)\n",
        "print('df_test shape:',  df.shape)\n",
        "\n",
        "X_Train = pd.DataFrame(df_final[:1460])\n",
        "X_Test  = pd.DataFrame(df_final[1460:])\n",
        "Y_Train = df['Mean price reduction percentage']\n",
        "\n",
        "print('\\nCheck that the datasets are consistent:\\n')\n",
        "print('X_train shape', X_Train.shape)\n",
        "print('Y_train shape:', Y_Train.shape)\n",
        "print('X_test shape:',  X_Test.shape)"
      ],
      "metadata": {
        "id": "C6_q84zqNtsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model selection and prediction\n"
      ],
      "metadata": {
        "id": "jLwHJSlrNxBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the training set into training and validation set\n",
        "\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_Train, Y_Train, train_size=0.8, test_size=0.2,random_state=0)\n"
      ],
      "metadata": {
        "id": "oG1WEAj4NzfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model_RFR = RandomForestRegressor()\n",
        "model_RFR.fit(X_train, Y_train)\n",
        "Y_pred = model_RFR.predict(X_valid)\n",
        "print(mean_absolute_error(Y_valid, Y_pred))"
      ],
      "metadata": {
        "id": "o_7pl7T6N09n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the metrics for the Random forest regression model\n",
        "score = model_RFR.score(X_valid, Y_valid, sample_weight=None)\n",
        "r2 = r2_score(Y_valid,Y_pred)\n",
        "mse = mean_squared_error(Y_valid, Y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "std = np.std(Y_valid)\n",
        "error = mean_absolute_error(Y_valid, Y_pred)\n",
        "\n",
        "# Print relevant metrics.\n",
        "print(f\"The score is {score}.\")\n",
        "print(f\"The r2 is {r2}.\")\n",
        "print(f\"The mean squared error is {mse}.\")\n",
        "print(f\"The root mean squared error is {rmse}.\")\n",
        "print(f\"The standard deviation is {std}.\")\n",
        "print(f\"The error is {error} \")"
      ],
      "metadata": {
        "id": "ylRAWXgKYhfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "model_GBR = GradientBoostingRegressor()\n",
        "model_GBR.fit(X_train, Y_train)\n",
        "Y_pred = model_GBR.predict(X_valid)\n",
        "print(mean_absolute_error(Y_valid, Y_pred))"
      ],
      "metadata": {
        "id": "DOtsHBLSN2rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the metrics for the Random forest regression model\n",
        "score = model_GBR.score(X_valid, Y_valid, sample_weight=None)\n",
        "r2 = r2_score(Y_valid,Y_pred)\n",
        "mse = mean_squared_error(Y_valid, Y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "std = np.std(Y_valid)\n",
        "error = mean_absolute_error(Y_valid, Y_pred)\n",
        "\n",
        "# Print relevant metrics.\n",
        "print(f\"The score is {score}.\")\n",
        "print(f\"The r2 is {r2}.\")\n",
        "print(f\"The mean squared error is {mse}.\")\n",
        "print(f\"The root mean squared error is {rmse}.\")\n",
        "print(f\"The standard deviation is {std}.\")\n",
        "print(f\"The error is {error} \")"
      ],
      "metadata": {
        "id": "MgI_vNJgZrsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "model_SGD = SGDRegressor()\n",
        "model_SGD.fit(X_train, Y_train)\n",
        "Y_pred = model_SGD.predict(X_valid)\n",
        "print(mean_absolute_error(Y_valid, Y_pred))"
      ],
      "metadata": {
        "id": "RR1Sqng8N4eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the metrics for the Random forest regression model\n",
        "score = model_SGD.score(X_valid, Y_valid, sample_weight=None)\n",
        "r2 = r2_score(Y_valid,Y_pred)\n",
        "mse = mean_squared_error(Y_valid, Y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "std = np.std(Y_valid)\n",
        "error = mean_absolute_error(Y_valid, Y_pred)\n",
        "\n",
        "# Print relevant metrics.\n",
        "print(f\"The score is {score}.\")\n",
        "print(f\"The r2 is {r2}.\")\n",
        "print(f\"The mean squared error is {mse}.\")\n",
        "print(f\"The root mean squared error is {rmse}.\")\n",
        "print(f\"The standard deviation is {std}.\")\n",
        "print(f\"The error is {error} \")"
      ],
      "metadata": {
        "id": "_3OZXqsFZxPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "model_XGBR = XGBRegressor(learning_rate=0.03,n_estimators=200,objective='reg:squarederror')\n",
        "model_XGBR.fit(X_train,Y_train)\n",
        "Y_pred = model_XGBR.predict(X_valid)\n",
        "print(mean_absolute_error(Y_valid, Y_pred))"
      ],
      "metadata": {
        "id": "3svz74EIN6EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.title('Comparison of Sale Price of Predicted and Actual values')\n",
        "plt.scatter(Y_Train,model_RFR.predict(X_Train),label='Random Forest')\n",
        "plt.scatter(Y_Train,model_XGBR.predict(X_Train),label='XGB')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "yhKfhensN8GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "model = XGBRegressor()\n",
        "\n",
        "n_estimators   = [100, 200, 500]\n",
        "learning_rates = [0.03,0.1,0.3]\n",
        "objectives     = ['reg:squarederror']\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators' : n_estimators,\n",
        "    'learning_rate':learning_rates,\n",
        "    'objective' : objectives\n",
        "    }\n",
        "\n",
        "grid_cv = GridSearchCV(estimator = model,\n",
        "            param_grid = hyperparameter_grid,\n",
        "            scoring = 'neg_mean_absolute_error',\n",
        "            return_train_score = True)\n",
        "\n",
        "grid_cv.fit(X_Train,Y_Train)"
      ],
      "metadata": {
        "id": "7bTaW3aLN9x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_cv.best_score_\n"
      ],
      "metadata": {
        "id": "44blSYHsN_jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_cv.best_estimator_\n"
      ],
      "metadata": {
        "id": "PL1ZuiKnOAsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_pred = random_cv.predict(X_valid)\n",
        "#print(mean_absolute_error(Y_valid, Y_pred))"
      ],
      "metadata": {
        "id": "q3XEg1fWOCLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = grid_cv.best_estimator_\n",
        "Y_pred = regressor.predict(X_valid)\n",
        "print(mean_absolute_error(Y_valid, Y_pred))"
      ],
      "metadata": {
        "id": "4hUna8KMODrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.title('Comparison of Price Reduction')\n",
        "plt.scatter(Y_Train,model_RFR.predict(X_Train),label='Random Forest')\n",
        "plt.scatter(Y_Train,model_XGBR.predict(X_Train),label='XGB')\n",
        "plt.scatter(Y_Train,regressor.predict(X_Train),label='Best model')\n",
        "plt.xlabel('Actual Value')\n",
        "plt.ylabel('Predicted Value')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "s-KmXxHLOFZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparation of Submission Data"
      ],
      "metadata": {
        "id": "R0HVAiMAOIZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_Pred = regressor.predict(X_Test)\n"
      ],
      "metadata": {
        "id": "Rw9SI_PmOKWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_Pred\n"
      ],
      "metadata": {
        "id": "X7zbAYO6OLpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_Pred.shape\n"
      ],
      "metadata": {
        "id": "Oz8RYLnwOM1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sub = pd.DataFrame()\n",
        "#sub['Mean days listing to pending'] = df['Mean days listing to pending']\n",
        "#sub['Mean price reduction percentage'] = Y_Pred"
      ],
      "metadata": {
        "id": "_YYIZVtROOcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjJnsIFEX3nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtDiD2jwYKHT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}